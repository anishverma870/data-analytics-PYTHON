{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the required Libraries.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reading & Data Types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data in pandas\n",
    "inp0= pd.read_csv(\"Attribute+DataSet (7).csv\")\n",
    "inp1= pd.read_csv(\"Dress+Sales (4).csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have “Attribute DataSet” which contains a column named “Price”. Choose the correct statement from the following about its data type and variable type.\n",
    "- Integer type and numerical variable\n",
    "- Object type and categorical ordinal variable\n",
    "- Object type and categorical nominal variable\n",
    "- Float type and categorical variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another column in “Attribute DataSet” named as “Recommendation”, choose the correct statement about its data type and variable type.\n",
    "- Integer type and categorical\n",
    "- Object type and categorical\n",
    "- Integer type and continuous numerical\n",
    "- Object type only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following column do you think are of no use in “Attribute DataSet”.\n",
    "- Dress_ID\n",
    "- Price\n",
    "- Size and material\n",
    "- NeckLine\n",
    "- None of the above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 24 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Dress_ID    479 non-null    float64\n",
      " 1   29-08-2013  479 non-null    int64  \n",
      " 2   31-08-2013  479 non-null    int64  \n",
      " 3   09-02-2013  479 non-null    int64  \n",
      " 4   09-04-2013  479 non-null    int64  \n",
      " 5   09-06-2013  479 non-null    int64  \n",
      " 6   09-08-2013  479 non-null    int64  \n",
      " 7   09-10-2013  479 non-null    int64  \n",
      " 8   09-12-2013  479 non-null    object \n",
      " 9   14-09-2013  479 non-null    object \n",
      " 10  16-09-2013  479 non-null    object \n",
      " 11  18-09-2013  479 non-null    object \n",
      " 12  20-09-2013  479 non-null    object \n",
      " 13  22-09-2013  479 non-null    object \n",
      " 14  24-09-2013  479 non-null    int64  \n",
      " 15  26-09-2013  257 non-null    float64\n",
      " 16  28-09-2013  479 non-null    int64  \n",
      " 17  30-09-2013  222 non-null    float64\n",
      " 18  10-02-2013  220 non-null    float64\n",
      " 19  10-04-2013  221 non-null    float64\n",
      " 20  10-06-2013  479 non-null    int64  \n",
      " 21  10-08-2013  224 non-null    float64\n",
      " 22  10-10-2013  224 non-null    float64\n",
      " 23  10-12-2013  479 non-null    int64  \n",
      "dtypes: float64(7), int64(11), object(6)\n",
      "memory usage: 89.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print the information about the attributes of inp0 and inp1.\n",
    "inp1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 479 entries, 0 to 478\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Dress_ID        479 non-null    int64  \n",
      " 1   Style           479 non-null    object \n",
      " 2   Price           477 non-null    object \n",
      " 3   Rating          479 non-null    float64\n",
      " 4   Size            479 non-null    object \n",
      " 5   Season          477 non-null    object \n",
      " 6   NeckLine        476 non-null    object \n",
      " 7   SleeveLength    477 non-null    object \n",
      " 8   Material        360 non-null    object \n",
      " 9   FabricType      223 non-null    object \n",
      " 10  Decoration      255 non-null    object \n",
      " 11  Pattern Type    377 non-null    object \n",
      " 12  Recommendation  479 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 48.8+ KB\n"
     ]
    }
   ],
   "source": [
    "inp0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the Rows and Columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is a column in “Attribute Dataset” named as ‘Size’. This column contains the values in abbreviation format. Write a code in Python to convert the followings:\n",
    "\n",
    "- M into  “Medium”\n",
    "- L into  “Large”\n",
    "- XL into “Extra large”\n",
    "- free into “Free”\n",
    "- S, s & small into “Small”.\n",
    "\n",
    "Now once you are done with changes in the dataset, what is the value of the lowest percentage, the highest percentage and the percentage of Small size categories in the column named “Size”?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Size\n",
       "M        171\n",
       "free     165\n",
       "L         93\n",
       "S         34\n",
       "XL        14\n",
       "small      1\n",
       "s          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp0['Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column fixing, correcting size abbreviation. count the percentage of each size category in \"Size\" column.\n",
    "inp0['Size'] = inp0['Size'].map({'M':'Medium','L':'Large','XL':'Extra large','free':'Free','S':'Small','s':'Small','small':'Small'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Size\n",
       "Medium         171\n",
       "Free           165\n",
       "Large           93\n",
       "Small           36\n",
       "Extra large     14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the value counts of each category in \"Size\" column.\n",
    "inp0['Size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute/Remove Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID            0\n",
       "Style               0\n",
       "Price               2\n",
       "Rating              0\n",
       "Size                0\n",
       "Season              2\n",
       "NeckLine            3\n",
       "SleeveLength        2\n",
       "Material          119\n",
       "FabricType        256\n",
       "Decoration        224\n",
       "Pattern Type      102\n",
       "Recommendation      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the null count of each variables of inp0 and inp1.\n",
    "inp0.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are given another dataset named “Dress Sales”. Now if you observe the datatypes of the columns using ‘inp1.info()’ command, you can identify that there are certain columns defined as object data type though they primarily consist of numeric data.\n",
    "\n",
    "Now if you try and convert these object data type columns into numeric data type(float), you will come across an error message. Try to correct this error.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID      float64\n",
       "29-08-2013      int64\n",
       "31-08-2013      int64\n",
       "09-02-2013      int64\n",
       "09-04-2013      int64\n",
       "09-06-2013      int64\n",
       "09-08-2013      int64\n",
       "09-10-2013      int64\n",
       "09-12-2013     object\n",
       "14-09-2013     object\n",
       "16-09-2013     object\n",
       "18-09-2013     object\n",
       "20-09-2013     object\n",
       "22-09-2013     object\n",
       "24-09-2013      int64\n",
       "26-09-2013    float64\n",
       "28-09-2013      int64\n",
       "30-09-2013    float64\n",
       "10-02-2013    float64\n",
       "10-04-2013    float64\n",
       "10-06-2013      int64\n",
       "10-08-2013    float64\n",
       "10-10-2013    float64\n",
       "10-12-2013      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the data types information of inp1 i.e. \"Dress Sales\" data.\n",
    "inp1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Removed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[294], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m inp1\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   6639\u001b[0m     ]\n\u001b[0;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    436\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Removed'"
     ]
    }
   ],
   "source": [
    "# Try to convert the object type into float type of data. YOU GET ERROR MESSAGE.\n",
    "inp1.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Dress_ID  29-08-2013  31-08-2013  09-02-2013  09-04-2013  09-06-2013  \\\n",
      "0  1.006033e+09        2114        2274        2491        2660        2727   \n",
      "1  1.212192e+09         151         275         570         750         813   \n",
      "2  1.190381e+09           6           7           7           7           8   \n",
      "3  9.660060e+08        1005        1128        1326        1455        1507   \n",
      "4  8.763395e+08         996        1175        1304        1396        1432   \n",
      "\n",
      "   09-08-2013  09-10-2013 09-12-2013 14-09-2013  ... 24-09-2013 26-09-2013  \\\n",
      "0        2887        2930       3119       3204  ...       3554     3624.0   \n",
      "1        1066        1164       1558       1756  ...       2710     2942.0   \n",
      "2           8           9         10         10  ...         11       11.0   \n",
      "3        1621        1637       1723       1746  ...       1878     1892.0   \n",
      "4        1559        1570        NaN       1655  ...       2032     2156.0   \n",
      "\n",
      "  28-09-2013 30-09-2013  10-02-2013  10-04-2013  10-06-2013  10-08-2013  \\\n",
      "0       3706     3746.0      3795.0      3832.0        3897      3923.0   \n",
      "1       3258     3354.0      3475.0      3654.0        3911      4024.0   \n",
      "2         11       11.0        11.0        11.0          11        11.0   \n",
      "3       1914     1924.0      1929.0      1941.0        1952      1955.0   \n",
      "4       2252     2312.0      2387.0      2459.0        2544      2614.0   \n",
      "\n",
      "   10-10-2013  10-12-2013  \n",
      "0      3985.0        4048  \n",
      "1      4125.0        4277  \n",
      "2        11.0          11  \n",
      "3      1959.0        1963  \n",
      "4      2693.0        2736  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Do the required changes in the \"Dress Sales\" data set to get null values on string values.\n",
    "\n",
    "\n",
    "# Add nulls to 10% of string columns\n",
    "for col in inp1.select_dtypes(include='object'):\n",
    "    inp1.loc[inp1.sample(frac=0.1).index, col] = np.nan\n",
    "\n",
    "# Show first few rows\n",
    "print(inp1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dress_ID      float64\n",
       " 29-08-2013      int64\n",
       " 31-08-2013      int64\n",
       " 09-02-2013      int64\n",
       " 09-04-2013      int64\n",
       " 09-06-2013      int64\n",
       " 09-08-2013      int64\n",
       " 09-10-2013      int64\n",
       " 09-12-2013    float64\n",
       " 14-09-2013    float64\n",
       " 16-09-2013    float64\n",
       " 18-09-2013    float64\n",
       " 20-09-2013    float64\n",
       " 22-09-2013    float64\n",
       " 24-09-2013      int64\n",
       " 26-09-2013    float64\n",
       " 28-09-2013      int64\n",
       " 30-09-2013    float64\n",
       " 10-02-2013    float64\n",
       " 10-04-2013    float64\n",
       " 10-06-2013      int64\n",
       " 10-08-2013    float64\n",
       " 10-10-2013    float64\n",
       " 10-12-2013      int64\n",
       " dtype: object,\n",
       "        Dress_ID  29-08-2013  31-08-2013  09-02-2013  09-04-2013  09-06-2013  \\\n",
       " 0  1.006033e+09        2114        2274        2491        2660        2727   \n",
       " 1  1.212192e+09         151         275         570         750         813   \n",
       " 2  1.190381e+09           6           7           7           7           8   \n",
       " 3  9.660060e+08        1005        1128        1326        1455        1507   \n",
       " 4  8.763395e+08         996        1175        1304        1396        1432   \n",
       " \n",
       "    09-08-2013  09-10-2013  09-12-2013  14-09-2013  ...  24-09-2013  \\\n",
       " 0        2887        2930      3119.0      3204.0  ...        3554   \n",
       " 1        1066        1164      1558.0      1756.0  ...        2710   \n",
       " 2           8           9        10.0        10.0  ...          11   \n",
       " 3        1621        1637      1723.0      1746.0  ...        1878   \n",
       " 4        1559        1570         NaN      1655.0  ...        2032   \n",
       " \n",
       "    26-09-2013  28-09-2013  30-09-2013  10-02-2013  10-04-2013  10-06-2013  \\\n",
       " 0      3624.0        3706      3746.0      3795.0      3832.0        3897   \n",
       " 1      2942.0        3258      3354.0      3475.0      3654.0        3911   \n",
       " 2        11.0          11        11.0        11.0        11.0          11   \n",
       " 3      1892.0        1914      1924.0      1929.0      1941.0        1952   \n",
       " 4      2156.0        2252      2312.0      2387.0      2459.0        2544   \n",
       " \n",
       "    10-08-2013  10-10-2013  10-12-2013  \n",
       " 0      3923.0      3985.0        4048  \n",
       " 1      4024.0      4125.0        4277  \n",
       " 2        11.0        11.0          11  \n",
       " 3      1955.0      1959.0        1963  \n",
       " 4      2614.0      2693.0        2736  \n",
       " \n",
       " [5 rows x 24 columns])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the object type columns in \"Dress Sales\" into float type of data type.\n",
    "# Convert object type columns to float (if possible)\n",
    "for col in inp1.select_dtypes(include='object'):\n",
    "    inp1[col] = pd.to_numeric(inp1[col], errors='coerce')\n",
    "\n",
    "# Show the updated data types and a preview\n",
    "updated_dtypes = inp1.dtypes\n",
    "df_preview_after_conversion = inp1.head()\n",
    "\n",
    "updated_dtypes, df_preview_after_conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID      float64\n",
       "29-08-2013      int64\n",
       "31-08-2013      int64\n",
       "09-02-2013      int64\n",
       "09-04-2013      int64\n",
       "09-06-2013      int64\n",
       "09-08-2013      int64\n",
       "09-10-2013      int64\n",
       "09-12-2013    float64\n",
       "14-09-2013    float64\n",
       "16-09-2013    float64\n",
       "18-09-2013    float64\n",
       "20-09-2013    float64\n",
       "22-09-2013    float64\n",
       "24-09-2013      int64\n",
       "26-09-2013    float64\n",
       "28-09-2013      int64\n",
       "30-09-2013    float64\n",
       "10-02-2013    float64\n",
       "10-04-2013    float64\n",
       "10-06-2013      int64\n",
       "10-08-2013    float64\n",
       "10-10-2013    float64\n",
       "10-12-2013      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "lia  = ['2','3','4','5']\n",
    "newli = pd.Series(data=lia,index=None,name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "newli = pd.to_numeric(newli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    3\n",
       "2    4\n",
       "3    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you see the null counts in “Dress Sales” dataset after performing all the operations that have been mentioned in jupyter notebook, you will find that there are some columns in “Dress Sales” data where there are more than 40% of missing values. Based on your understanding of dealing with missing values do the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID       0.000000\n",
       "29-08-2013     0.000000\n",
       "31-08-2013     0.000000\n",
       "09-02-2013     0.000000\n",
       "09-04-2013     0.000000\n",
       "09-06-2013     0.000000\n",
       "09-08-2013     0.000000\n",
       "09-10-2013     0.000000\n",
       "09-12-2013    10.229645\n",
       "14-09-2013    10.229645\n",
       "16-09-2013    10.229645\n",
       "18-09-2013    10.229645\n",
       "20-09-2013    10.229645\n",
       "22-09-2013    10.229645\n",
       "24-09-2013     0.000000\n",
       "26-09-2013    46.346555\n",
       "28-09-2013     0.000000\n",
       "30-09-2013    53.653445\n",
       "10-02-2013    54.070981\n",
       "10-04-2013    53.862213\n",
       "10-06-2013     0.000000\n",
       "10-08-2013    53.235908\n",
       "10-10-2013    53.235908\n",
       "10-12-2013     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the null percetange of each column of inp1.\n",
    "inp1.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns in \"Dress Sales\" which have more than 40% of missing values.\n",
    "null_value = inp1.isnull().mean()*100\n",
    "\n",
    "find_to_drop = null_value[null_value > 40].index\n",
    "inp1.drop(columns=find_to_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID       0.000000\n",
       "29-08-2013     0.000000\n",
       "31-08-2013     0.000000\n",
       "09-02-2013     0.000000\n",
       "09-04-2013     0.000000\n",
       "09-06-2013     0.000000\n",
       "09-08-2013     0.000000\n",
       "09-10-2013     0.000000\n",
       "09-12-2013    10.229645\n",
       "14-09-2013    10.229645\n",
       "16-09-2013    10.229645\n",
       "18-09-2013    10.229645\n",
       "20-09-2013    10.229645\n",
       "22-09-2013    10.229645\n",
       "24-09-2013     0.000000\n",
       "28-09-2013     0.000000\n",
       "10-06-2013     0.000000\n",
       "10-12-2013     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should categorise the dates into seasons in “Dress Sales” data to simplify the analysis according to the following criteria:\n",
    "- June, July and August: Summer.\n",
    "- September, October and November: Autumn.\n",
    "- December, January and February: WInter.\n",
    "- March, April and May: Spring.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dress_ID', '29-08-2013', '31-08-2013', '09-02-2013', '09-04-2013',\n",
       "       '09-06-2013', '09-08-2013', '09-10-2013', '09-12-2013', '14-09-2013',\n",
       "       '16-09-2013', '18-09-2013', '20-09-2013', '22-09-2013', '24-09-2013',\n",
       "       '28-09-2013', '10-06-2013', '10-12-2013'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Autumn</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.006033e+09</td>\n",
       "      <td>13899</td>\n",
       "      <td>16671.0</td>\n",
       "      <td>9658.0</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.212192e+09</td>\n",
       "      <td>6216</td>\n",
       "      <td>17311.0</td>\n",
       "      <td>6405.0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.190381e+09</td>\n",
       "      <td>40</td>\n",
       "      <td>82.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.660060e+08</td>\n",
       "      <td>7213</td>\n",
       "      <td>14411.0</td>\n",
       "      <td>5012.0</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.763395e+08</td>\n",
       "      <td>7706</td>\n",
       "      <td>14676.0</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dress_ID  Summer   Autumn  Winter  Spring\n",
       "0  1.006033e+09   13899  16671.0  9658.0    2660\n",
       "1  1.212192e+09    6216  17311.0  6405.0     750\n",
       "2  1.190381e+09      40     82.0    28.0       7\n",
       "3  9.660060e+08    7213  14411.0  5012.0    1455\n",
       "4  8.763395e+08    7706  14676.0  4040.0    1396"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the four seasons columns in inp1, according to the above criteria.\n",
    "from datetime import datetime\n",
    "\n",
    "# Extract date columns (excluding 'Dress_ID')\n",
    "date_columns = [col for col in inp1.columns if col != 'Dress_ID']\n",
    "\n",
    "# Function to determine the season from a date\n",
    "def get_season(date_str):\n",
    "    try:\n",
    "        date = datetime.strptime(date_str, '%d-%m-%Y')\n",
    "        month = date.month\n",
    "        if month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        elif month in [9, 10, 11]:\n",
    "            return 'Autumn'\n",
    "        elif month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        else:\n",
    "            return 'Spring'\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Map each date column to its corresponding season\n",
    "season_map = {col: get_season(col) for col in date_columns}\n",
    "\n",
    "# Group columns by season and calculate total sales for each season per dress\n",
    "seasonal_sales = pd.DataFrame()\n",
    "seasonal_sales['Dress_ID'] = inp1['Dress_ID']\n",
    "\n",
    "for season in ['Summer', 'Autumn', 'Winter', 'Spring']:\n",
    "    cols = [col for col in date_columns if season_map[col] == season]\n",
    "    seasonal_sales[season] = inp1[cols].sum(axis=1)\n",
    "\n",
    "seasonal_sales.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sum of sales in each seasons in inp1 i.e. \"Dress Sales\".\n",
    "inp1 = pd.merge(inp1,seasonal_sales,on = 'Dress_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Summer     691907.0\n",
       "Autumn    1271354.0\n",
       "Winter     460536.0\n",
       "Spring     143600.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp1[['Summer','Autumn','Winter','Spring']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge inp1 with inp0 with left join manner, so that the information of inp0 should remain intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Style</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Size</th>\n",
       "      <th>Season</th>\n",
       "      <th>NeckLine</th>\n",
       "      <th>SleeveLength</th>\n",
       "      <th>Material</th>\n",
       "      <th>FabricType</th>\n",
       "      <th>...</th>\n",
       "      <th>20-09-2013</th>\n",
       "      <th>22-09-2013</th>\n",
       "      <th>24-09-2013</th>\n",
       "      <th>28-09-2013</th>\n",
       "      <th>10-06-2013</th>\n",
       "      <th>10-12-2013</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Autumn</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3554</td>\n",
       "      <td>3706</td>\n",
       "      <td>3897</td>\n",
       "      <td>4048</td>\n",
       "      <td>13899</td>\n",
       "      <td>16671.0</td>\n",
       "      <td>9658.0</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Large</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>Petal</td>\n",
       "      <td>microfiber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2106.0</td>\n",
       "      <td>2454.0</td>\n",
       "      <td>2710</td>\n",
       "      <td>3258</td>\n",
       "      <td>3911</td>\n",
       "      <td>4277</td>\n",
       "      <td>6216</td>\n",
       "      <td>17311.0</td>\n",
       "      <td>6405.0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>vintage</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Large</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>82.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Large</td>\n",
       "      <td>Spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>silk</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>1878</td>\n",
       "      <td>1914</td>\n",
       "      <td>1952</td>\n",
       "      <td>1963</td>\n",
       "      <td>7213</td>\n",
       "      <td>14411.0</td>\n",
       "      <td>5012.0</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>cute</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>chiffonfabric</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>2032</td>\n",
       "      <td>2252</td>\n",
       "      <td>2544</td>\n",
       "      <td>2736</td>\n",
       "      <td>7706</td>\n",
       "      <td>14676.0</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dress_ID    Style    Price  Rating    Size  Season NeckLine SleeveLength  \\\n",
       "0  1006032852     Sexy      Low     4.6  Medium  Summer   o-neck    sleevless   \n",
       "1  1212192089   Casual      Low     0.0   Large  Summer   o-neck        Petal   \n",
       "2  1190380701  vintage     High     0.0   Large  Automn   o-neck         full   \n",
       "3   966005983    Brief  Average     4.6   Large  Spring   o-neck         full   \n",
       "4   876339541     cute      Low     4.5  Medium  Summer   o-neck    butterfly   \n",
       "\n",
       "        Material FabricType  ... 20-09-2013 22-09-2013  24-09-2013  \\\n",
       "0            NaN    chiffon  ...        NaN        NaN        3554   \n",
       "1     microfiber        NaN  ...     2106.0     2454.0        2710   \n",
       "2       polyster        NaN  ...       10.0       11.0          11   \n",
       "3           silk    chiffon  ...     1812.0     1845.0        1878   \n",
       "4  chiffonfabric    chiffon  ...     1824.0     1919.0        2032   \n",
       "\n",
       "   28-09-2013  10-06-2013  10-12-2013  Summer   Autumn  Winter  Spring  \n",
       "0        3706        3897        4048   13899  16671.0  9658.0    2660  \n",
       "1        3258        3911        4277    6216  17311.0  6405.0     750  \n",
       "2          11          11          11      40     82.0    28.0       7  \n",
       "3        1914        1952        1963    7213  14411.0  5012.0    1455  \n",
       "4        2252        2544        2736    7706  14676.0  4040.0    1396  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge inp0 with inp1 into inp0. this is also called left merge.\n",
    "inp0 = pd.merge(left=inp0,right=inp1, how='left', left_on='Dress_ID', right_on='Dress_ID')\n",
    "inp0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dress_ID', 'Style', 'Price', 'Rating', 'Size', 'Season', 'NeckLine',\n",
       "       'SleeveLength', 'Material', 'FabricType', 'Decoration', 'Pattern Type',\n",
       "       'Recommendation', '29-08-2013', '31-08-2013', '09-02-2013',\n",
       "       '09-04-2013', '09-06-2013', '09-08-2013', '09-10-2013', '09-12-2013',\n",
       "       '14-09-2013', '16-09-2013', '18-09-2013', '20-09-2013', '22-09-2013',\n",
       "       '24-09-2013', '28-09-2013', '10-06-2013', '10-12-2013', 'Summer',\n",
       "       'Autumn', 'Winter', 'Spring'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'29-08-2013_x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '29-08-2013_x'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[326], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Now Drop the Date columns from inp0 as it is already combined into four seasons.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m inp0\u001b[38;5;241m.\u001b[39mdrop(inp0\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m29-08-2013_x\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m10-12-2013_x\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns, axis\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m inp0\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1377\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1020\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1020\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(retval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39m_getitem_axis(key, axis\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1411\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getbool_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1443\u001b[0m, in \u001b[0;36m_LocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1442\u001b[0m labels \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1443\u001b[0m indexer \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mslice_indexer(slice_obj\u001b[38;5;241m.\u001b[39mstart, slice_obj\u001b[38;5;241m.\u001b[39mstop, slice_obj\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   1446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_slice(indexer, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6662\u001b[0m, in \u001b[0;36mIndex.slice_indexer\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6618\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mslice_indexer\u001b[39m(\n\u001b[0;32m   6619\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   6620\u001b[0m     start: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6621\u001b[0m     end: Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6622\u001b[0m     step: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   6623\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mslice\u001b[39m:\n\u001b[0;32m   6624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6625\u001b[0m \u001b[38;5;124;03m    Compute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[0;32m   6626\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6660\u001b[0m \u001b[38;5;124;03m    slice(1, 3, None)\u001b[39;00m\n\u001b[0;32m   6661\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6662\u001b[0m     start_slice, end_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_locs(start, end, step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[0;32m   6664\u001b[0m     \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[0;32m   6665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6879\u001b[0m, in \u001b[0;36mIndex.slice_locs\u001b[1;34m(self, start, end, step)\u001b[0m\n\u001b[0;32m   6877\u001b[0m start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   6878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 6879\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_slice_bound(start, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   6881\u001b[0m     start_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6804\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side)\u001b[0m\n\u001b[0;32m   6801\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_searchsorted_monotonic(label, side)\n\u001b[0;32m   6802\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   6803\u001b[0m         \u001b[38;5;66;03m# raise the original KeyError\u001b[39;00m\n\u001b[1;32m-> 6804\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m   6806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(slc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m   6807\u001b[0m     \u001b[38;5;66;03m# get_loc may return a boolean array, which\u001b[39;00m\n\u001b[0;32m   6808\u001b[0m     \u001b[38;5;66;03m# is OK as long as they are representable by a slice.\u001b[39;00m\n\u001b[0;32m   6809\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m is_bool_dtype(slc\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6798\u001b[0m, in \u001b[0;36mIndex.get_slice_bound\u001b[1;34m(self, label, side)\u001b[0m\n\u001b[0;32m   6796\u001b[0m \u001b[38;5;66;03m# we need to look up the label\u001b[39;00m\n\u001b[0;32m   6797\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6798\u001b[0m     slc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   6799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   6800\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '29-08-2013_x'"
     ]
    }
   ],
   "source": [
    "# Now Drop the Date columns from inp0 as it is already combined into four seasons.\n",
    "inp0.drop(inp0.loc[:,'29-08-2013_x':'10-12-2013_x'].columns, axis= 1, inplace= True)\n",
    "inp0.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the null count of inp0 to get the idea about the missing values in data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID            0\n",
       "Style               0\n",
       "Price               2\n",
       "Rating              0\n",
       "Size                0\n",
       "Season              2\n",
       "NeckLine            3\n",
       "SleeveLength        2\n",
       "Material          119\n",
       "FabricType        256\n",
       "Decoration        224\n",
       "Pattern Type      102\n",
       "Recommendation      0\n",
       "29-08-2013          0\n",
       "31-08-2013          0\n",
       "09-02-2013          0\n",
       "09-04-2013          0\n",
       "09-06-2013          0\n",
       "09-08-2013          0\n",
       "09-10-2013          0\n",
       "09-12-2013         49\n",
       "14-09-2013         49\n",
       "16-09-2013         49\n",
       "18-09-2013         49\n",
       "20-09-2013         49\n",
       "22-09-2013         49\n",
       "24-09-2013          0\n",
       "28-09-2013          0\n",
       "10-06-2013          0\n",
       "10-12-2013          0\n",
       "Summer              0\n",
       "Autumn              0\n",
       "Winter              0\n",
       "Spring              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the null count of each columns in inp0 dataframe i.e. combined data frame of inp0 and inp1 without date columns.\n",
    "inp0.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are two types of variables one with a large number of missing values and another is very less number of missing values. These two columns can be categorized as:\n",
    "\n",
    "Type-1: Missing values are very less (around 2 or 3 missing values): Price, Season, NeckLine, SleeveLength, Winter and Autumn. \n",
    "\n",
    "Type-2: Missing values are large in numbers (more than 15%): Material, FabricType, Decoration and Pattern Type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with the missing values of Type-1 columns: Price, Season, NeckLine, SleeveLength, Winter and Autumn.\n",
    "inp0['Price'] = inp0['Price'].fillna(inp0['Price'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['NeckLine'] = inp0['NeckLine'].fillna(inp0['NeckLine'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['Season'] = inp0['Season'].fillna(inp0['Season'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['SleeveLength'] = inp0['SleeveLength'].fillna(inp0['SleeveLength'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['Winter'] = inp0['Winter'].fillna(inp0['Winter'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['Autumn'] = inp0['Autumn'].fillna(inp0['Autumn'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dress_ID            0\n",
       "Style               0\n",
       "Price               0\n",
       "Rating              0\n",
       "Size                0\n",
       "Season              0\n",
       "NeckLine            0\n",
       "SleeveLength        0\n",
       "Material          119\n",
       "FabricType        256\n",
       "Decoration        224\n",
       "Pattern Type      102\n",
       "Recommendation      0\n",
       "29-08-2013          0\n",
       "31-08-2013          0\n",
       "09-02-2013          0\n",
       "09-04-2013          0\n",
       "09-06-2013          0\n",
       "09-08-2013          0\n",
       "09-10-2013          0\n",
       "09-12-2013         49\n",
       "14-09-2013         49\n",
       "16-09-2013         49\n",
       "18-09-2013         49\n",
       "20-09-2013         49\n",
       "22-09-2013         49\n",
       "24-09-2013          0\n",
       "28-09-2013          0\n",
       "10-06-2013          0\n",
       "10-12-2013          0\n",
       "Summer              0\n",
       "Autumn              0\n",
       "Winter              0\n",
       "Spring              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp0.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dress_ID</th>\n",
       "      <th>Style</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Size</th>\n",
       "      <th>Season</th>\n",
       "      <th>NeckLine</th>\n",
       "      <th>SleeveLength</th>\n",
       "      <th>Material</th>\n",
       "      <th>FabricType</th>\n",
       "      <th>...</th>\n",
       "      <th>20-09-2013</th>\n",
       "      <th>22-09-2013</th>\n",
       "      <th>24-09-2013</th>\n",
       "      <th>28-09-2013</th>\n",
       "      <th>10-06-2013</th>\n",
       "      <th>10-12-2013</th>\n",
       "      <th>Summer</th>\n",
       "      <th>Autumn</th>\n",
       "      <th>Winter</th>\n",
       "      <th>Spring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006032852</td>\n",
       "      <td>Sexy</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>sleevless</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3554</td>\n",
       "      <td>3706</td>\n",
       "      <td>3897</td>\n",
       "      <td>4048</td>\n",
       "      <td>13899</td>\n",
       "      <td>16671.0</td>\n",
       "      <td>9658.0</td>\n",
       "      <td>2660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1212192089</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Low</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Large</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>Petal</td>\n",
       "      <td>microfiber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2106.0</td>\n",
       "      <td>2454.0</td>\n",
       "      <td>2710</td>\n",
       "      <td>3258</td>\n",
       "      <td>3911</td>\n",
       "      <td>4277</td>\n",
       "      <td>6216</td>\n",
       "      <td>17311.0</td>\n",
       "      <td>6405.0</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1190380701</td>\n",
       "      <td>vintage</td>\n",
       "      <td>High</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Large</td>\n",
       "      <td>Automn</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>polyster</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>82.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>966005983</td>\n",
       "      <td>Brief</td>\n",
       "      <td>Average</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Large</td>\n",
       "      <td>Spring</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>full</td>\n",
       "      <td>silk</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>1878</td>\n",
       "      <td>1914</td>\n",
       "      <td>1952</td>\n",
       "      <td>1963</td>\n",
       "      <td>7213</td>\n",
       "      <td>14411.0</td>\n",
       "      <td>5012.0</td>\n",
       "      <td>1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>876339541</td>\n",
       "      <td>cute</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Summer</td>\n",
       "      <td>o-neck</td>\n",
       "      <td>butterfly</td>\n",
       "      <td>chiffonfabric</td>\n",
       "      <td>chiffon</td>\n",
       "      <td>...</td>\n",
       "      <td>1824.0</td>\n",
       "      <td>1919.0</td>\n",
       "      <td>2032</td>\n",
       "      <td>2252</td>\n",
       "      <td>2544</td>\n",
       "      <td>2736</td>\n",
       "      <td>7706</td>\n",
       "      <td>14676.0</td>\n",
       "      <td>4040.0</td>\n",
       "      <td>1396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dress_ID    Style    Price  Rating    Size  Season NeckLine SleeveLength  \\\n",
       "0  1006032852     Sexy      Low     4.6  Medium  Summer   o-neck    sleevless   \n",
       "1  1212192089   Casual      Low     0.0   Large  Summer   o-neck        Petal   \n",
       "2  1190380701  vintage     High     0.0   Large  Automn   o-neck         full   \n",
       "3   966005983    Brief  Average     4.6   Large  Spring   o-neck         full   \n",
       "4   876339541     cute      Low     4.5  Medium  Summer   o-neck    butterfly   \n",
       "\n",
       "        Material FabricType  ... 20-09-2013 22-09-2013  24-09-2013  \\\n",
       "0            NaN    chiffon  ...        NaN        NaN        3554   \n",
       "1     microfiber        NaN  ...     2106.0     2454.0        2710   \n",
       "2       polyster        NaN  ...       10.0       11.0          11   \n",
       "3           silk    chiffon  ...     1812.0     1845.0        1878   \n",
       "4  chiffonfabric    chiffon  ...     1824.0     1919.0        2032   \n",
       "\n",
       "   28-09-2013  10-06-2013  10-12-2013  Summer   Autumn  Winter  Spring  \n",
       "0        3706        3897        4048   13899  16671.0  9658.0    2660  \n",
       "1        3258        3911        4277    6216  17311.0  6405.0     750  \n",
       "2          11          11          11      40     82.0    28.0       7  \n",
       "3        1914        1952        1963    7213  14411.0  5012.0    1455  \n",
       "4        2252        2544        2736    7706  14676.0  4040.0    1396  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deal with the missing values for Type-2 columns: Material, FabricType, Decoration and Pattern Type.\n",
    "inp0.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "✅ Recommended Approaches:\n",
    "🔸 Option 1: Fill with 'Unknown' or 'Not Specified'\n",
    "This keeps all rows intact and clearly marks missing info:\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "for col in ['Material', 'FabricType', 'Decoration', 'Pattern Type']:\n",
    "    inp0[col] = inp0[col].fillna('Unknown')\n",
    "🔸 Option 2: Drop these columns (if they’re not useful for your analysis or model)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "inp0 = inp0.drop(columns=['Material', 'FabricType', 'Decoration', 'Pattern Type'])\n",
    "🔸 Option 3: Impute with mode (if you want to keep categories consistent)\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "for col in ['Material', 'FabricType', 'Decoration', 'Pattern Type']:\n",
    "    inp0[col] = inp0[col].fillna(inp0[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Material', 'FabricType', 'Decoration', 'Pattern Type'] :\n",
    "    inp0[col] = inp0[col].fillna(inp0[col].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardise value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the given dataset, there are certain discrepancies with the categorical names such as irregular spellings. Choose the correct option of columns with irregular categories and update them.\n",
    " \n",
    "- Season, NeckLine\n",
    "- Price, Material\n",
    "- fabricType, Decoration\n",
    "- Season, SleeveLength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correcting the spellings.\n",
    "inp0['Season'] = inp0['Season'].str.lower().replace({'automn':'autumn'}).str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['NeckLine'] = inp0['NeckLine'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O-neck', 'V-neck', 'Boat-neck', 'Peterpan-collor', 'Ruffled',\n",
       "       'Turndowncollor', 'Slash-neck', 'Mandarin-collor', 'Open',\n",
       "       'Sqare-collor', 'Sweetheart', 'Scoop', 'Halter', 'Backless',\n",
       "       'Bowneck'], dtype=object)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp0['NeckLine'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price\n",
       "Average      242\n",
       "Low          165\n",
       "Medium        30\n",
       "High          21\n",
       "very-high     21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correcting the Spellings.\n",
    "inp0['Price'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['Material'] = inp0['Material'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['FabricType'] = inp0['FabricType'].str.lower().replace({'shiffon':'chiffon','satin':'sattin','woolen':'wollen','flannael':'flannel'}).str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['Decoration'] = inp0['Decoration'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp0['SleeveLength']= inp0['SleeveLength'].str.lower().replace({\n",
    "    'sleevless':'sleeveless','sleeevless':'sleeveless','sleveless':'sleeveless',\n",
    "    'half':'halfsleeve','thressqatar':'threequarter','threequater':'threequarter','cap-sleeves':'capsleeves',\n",
    "    'urndowncollor':'turndowncollor'\n",
    "}).str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Unordered Univariate Analysis\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a column named ‘Style’ in ‘Attribute Dataset’ which consists of the different style categories of the women apparels. Certain categories whose total sale is less than 50000 across all the seasons is considered under one single category as ‘Others’.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following categories in ‘Style’ column can be grouped into ‘Others’ category? and perform the grouping operation in the notebook for further analysis.\n",
    "- Flare, fashion\n",
    "- Novelty, bohemian\n",
    "- OL, fashion, work\n",
    "- Novelty, fashion, Flare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"Style\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of “cute” and “Others” category in “Style” column in “Attribute DataSet” respectively?\n",
    "- 46%, 5%\n",
    "- 9%, 2.1%\n",
    "- 2.1%, 5%\n",
    "- 13.8%, 9%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of each categories in the \"Style\" variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly Club Neckline, SLeeve length categories into \"Others\" which have less than 50000 sales across all the seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"Neckline\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"Sleeve length\" categories into \"Others\" which have less than 50000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Club material, fabrictype, patterntype and decoration categories into \"Others\" which have less than 25000 sales across all the seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"material\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"fabric type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"patern type\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group \"decoration\" categories into \"Others\" which have less than 25000 sales across all the seasons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caregorical Ordered Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following is an unordered variable in “Attribute DataSet”.\n",
    "- Style\n",
    "- Price\n",
    "- Season\n",
    "- Size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variable Univariate analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the approximate difference between the maximum value and 75th percentile in “Autumn” column.\n",
    "- Approx 54000\n",
    "- Approx 55000\n",
    "- Approx 52000\n",
    "- Approx 50000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the numerical variale: \"Autumn\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the boxplot of \"Autumn\" column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following season has the highest difference between the maximum value and 99th quantile of sales?\n",
    "- Winter\n",
    "- Summer\n",
    "- Spring\n",
    "- Autumn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Winter season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Summer season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Spring season.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum and 99th percentile of Autumn season.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical- Categorical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following “Price” category has the lowest average value of rating?\n",
    "- very-high\n",
    "- Medium\n",
    "- Low\n",
    "- High\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the Mean of Ratings for each Price category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median of the rating of “vintage” category in Style column?\n",
    "- 4.6\n",
    "- 4.7\n",
    "- 4.55\n",
    "- 0.00\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the median of Ratings for each Style category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following season has the highest average value of sale for “Recommendation” value equals to 1.\n",
    "- Summer\n",
    "- Spring\n",
    "- Autumn\n",
    "- Winter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer sale vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spring sale vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autumn sale vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Winter sale vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical categorical bivariate analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following size categories has the highest positive recommendations?\n",
    "- Medium and extra large\n",
    "- Extra large and small\n",
    "- Free and small\n",
    "- Free and medium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size vs Recommendation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following pair of “Style” and “Price” category has the highest average of positive recommendations?\n",
    "- Price: medium and style: vintage\n",
    "- Price: medium and style: cute\n",
    "- Price: very high and style: party\n",
    "- Price: low and style: sexy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heat map of Style, price and Recommendation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following material type has no recommendation in summer and winter seasons?\n",
    "- Mix and Milksilk\n",
    "- Nylon and Rayon\n",
    "- Microfiber and Silk\n",
    "- Milksilk and Microfiber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the heat map of Season, material and Recommendation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
