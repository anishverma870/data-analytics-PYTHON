{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4b4847-fd1c-4099-ade8-c36b9c767e8f",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "# File paths\n",
    "csv_file = \"C:\\\\Users\\\\anish\\\\OneDrive\\\\Documents\\\\GitHub\\\\mainfolder\\\\sales_data.csv\"\n",
    "json_folder = \"C:\\\\Users\\\\anish\\\\OneDrive\\\\Documents\\\\GitHub\\\\mainfolder\\\\product_details\"\n",
    "txt_folder = \"C:\\\\Users\\\\anish\\\\OneDrive\\\\Documents\\\\GitHub\\\\mainfolder\\\\product_descriptions\"\n",
    "\n",
    "'''def load_sales_data(csv_file):\n",
    "    \"\"\"Load sales data from a CSV file and return as a dictionary.\"\"\"\n",
    "    if os.path.exists(csv_file):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        return {row[\"Product_SKU\"]: row.iloc[1:].tolist() for _, row in df.iterrows()}\n",
    "    else:\n",
    "        return {}'''\n",
    "\n",
    "\n",
    "def load_sales_data(csv_file):\n",
    "    \"\"\"Load sales data from a CSV file and return as a dictionary.\"\"\"\n",
    "    if os.path.exists(csv_file):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Ensure 'Product_SKU' column exists\n",
    "        if \"Product_SKU\" not in df.columns:\n",
    "            print(\"‚ùå Error: 'Product_SKU' column not found in CSV!\")\n",
    "            return {}\n",
    "\n",
    "        # Fill missing values with 0 and ensure numerical data\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        # Convert all day columns to integers\n",
    "        for col in df.columns[1:]:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "        # Return data as a dictionary\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        print(\"‚ùå Error: CSV file not found!\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if file doesn't exist\n",
    "\n",
    "# Load sales data\n",
    "df_sales = load_sales_data(csv_file)\n",
    "\n",
    "if not df_sales.empty:\n",
    "    print(\"\\nüìä SALES DATA TABLE:\\n\")\n",
    "\n",
    "    # Display data in tabular format without using tabulate\n",
    "    print(df_sales.to_string(index=False))  # Prints DataFrame in a structured table-like format\n",
    "else:\n",
    "    print(\"‚ö† No sales data available.\")\n",
    "\n",
    "\n",
    "def load_product_details(json_folder):\n",
    "    \"\"\"Load product details from JSON files.\"\"\"\n",
    "    product_details = {}\n",
    "    if os.path.exists(json_folder):\n",
    "        for filename in os.listdir(json_folder):\n",
    "            if filename.startswith(\"details_\") and filename.endswith('.json'):\n",
    "                sku = filename.replace(\"details_\", \"\").replace('.json', '')\n",
    "                with open(os.path.join(json_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                    product_details[sku] = json.load(file)\n",
    "    return product_details\n",
    "\n",
    "def load_product_descriptions(txt_folder):\n",
    "    \"\"\"Load product descriptions from text files.\"\"\"\n",
    "    product_descriptions = {}\n",
    "    if os.path.exists(txt_folder):\n",
    "        for filename in os.listdir(txt_folder):\n",
    "            if filename.startswith(\"description_\") and filename.endswith('.txt'):\n",
    "                sku = filename.replace(\"description_\", \"\").replace('.txt', '')\n",
    "                with open(os.path.join(txt_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                    product_descriptions[sku] = file.read().strip()\n",
    "    return product_descriptions\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load all required data files into structured formats and display in a formatted way.\"\"\"\n",
    "    sales_data = load_sales_data(csv_file)\n",
    "    product_details = load_product_details(json_folder)\n",
    "    product_descriptions = load_product_descriptions(txt_folder)\n",
    "\n",
    "    # Convert sales_data dictionary to DataFrame for better readability\n",
    "    df_sales = pd.DataFrame.from_dict(sales_data, orient='index', columns=[f\"Day{i}\" for i in range(1, 15)])\n",
    "    df_sales.insert(0, \"Product_SKU\", df_sales.index)  # Insert SKU column at the beginning\n",
    "\n",
    "    # Display sales data in tabular format\n",
    "    print(\"\\nüìä SALES DATA TABLE:\\n\")\n",
    "    print(tabulate(df_sales, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "\n",
    "    # Display product details in readable JSON format\n",
    "    print(\"\\nüì¶ PRODUCT DETAILS:\\n\")\n",
    "    for sku, details in product_details.items():\n",
    "        print(f\"SKU: {sku}\")\n",
    "        print(json.dumps(details, indent=4))  # Pretty-print JSON\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Display product descriptions\n",
    "    print(\"\\nüìù PRODUCT DESCRIPTIONS:\\n\")\n",
    "    for sku, description in product_descriptions.items():\n",
    "        print(f\"SKU: {sku}\")\n",
    "        print(description)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return sales_data, product_details, product_descriptions\n",
    "\n",
    "# Load initial data\n",
    "sales_data, product_details, product_descriptions = load_data()\n",
    "print(\"‚úÖ Data Loaded Successfully\")\n",
    "\n",
    "def validate_sku(sku):\n",
    "    \"\"\"Validate SKU: It should be exactly 13 characters, alphanumeric, and uppercase.\"\"\"\n",
    "    return bool(re.fullmatch(r\"[A-Z0-9]{13}\", sku))\n",
    "\n",
    "def validate_sales_data(data):\n",
    "    \"\"\"Validate sales data: It should be 14 whole numbers separated by spaces.\"\"\"\n",
    "    numbers = data.split()\n",
    "    return len(numbers) == 14 and all(num.isdigit() for num in numbers)\n",
    "\n",
    "def update_sales_data():\n",
    "    \"\"\"Update or add sales data for a product SKU.\"\"\"\n",
    "    global sales_data\n",
    "    \n",
    "    sku = input(\"Enter Product Sales SKU: \").strip()\n",
    "    if not validate_sku(sku):\n",
    "        print(\"‚ùå Invalid SKU! It should be exactly 13 characters, alphanumeric, and uppercase.\")\n",
    "        return\n",
    "    \n",
    "    if sku in sales_data:\n",
    "        choice = input(\"This SKU ID is found. Do you want to update the data? (yes/no): \").strip().lower()\n",
    "        if choice != 'yes':\n",
    "            return\n",
    "        day = input(\"Enter specific day to update (1-14) or press Enter to update all days: \")\n",
    "        if day:\n",
    "            day = int(day)\n",
    "            sales = int(input(f\"Enter sales data for Day {day}: \"))\n",
    "            sales_data[sku][day - 1] = sales\n",
    "        else:\n",
    "            sales_data_input = input(\"Enter sales data for all 14 days (separated by spaces): \")\n",
    "            if not validate_sales_data(sales_data_input):\n",
    "                print(\"‚ùå Invalid sales data! It should contain exactly 14 whole numbers separated by spaces.\")\n",
    "                return\n",
    "            sales_data[sku] = list(map(int, sales_data_input.split()))\n",
    "    else:\n",
    "        choice = input(\"This SKU ID is not found. Do you want to add new data? (yes/no): \").strip().lower()\n",
    "        if choice != 'yes':\n",
    "            return\n",
    "        sales_data_input = input(\"Enter sales data for all 14 days (separated by spaces): \")\n",
    "        if not validate_sales_data(sales_data_input):\n",
    "            print(\"‚ùå Invalid sales data! It should contain exactly 14 whole numbers separated by spaces.\")\n",
    "            return\n",
    "        sales_data[sku] = list(map(int, sales_data_input.split()))\n",
    "\n",
    "    print(\"‚úÖ Sales data updated successfully!\")\n",
    "\n",
    "def update_product_details():\n",
    "    \"\"\"Update or add product details in JSON format.\"\"\"\n",
    "    sku = input(\"Enter Product Detail SKU: \").strip()\n",
    "    if not validate_sku(sku):\n",
    "        print(\"‚ùå Invalid SKU!\")\n",
    "        return\n",
    "    \n",
    "    details = {\n",
    "        \"product_name\": input(\"Enter Product Name: \"),\n",
    "        \"brand\": input(\"Enter Brand: \"),\n",
    "        \"model\": input(\"Enter Model: \"),\n",
    "        \"specifications\": input(\"Enter Specifications: \"),\n",
    "        \"price\": input(\"Enter Price: \"),\n",
    "        \"availability\": input(\"Enter Availability: \")\n",
    "    }\n",
    "    \n",
    "    product_details[sku] = details\n",
    "    print(\"‚úÖ Product details updated successfully!\")\n",
    "\n",
    "def update_product_description():\n",
    "    \"\"\"Update or add product description in a text file.\"\"\"\n",
    "    sku = input(\"Enter Product Description SKU: \").strip()\n",
    "    if not validate_sku(sku):\n",
    "        print(\"‚ùå Invalid SKU!\")\n",
    "        return\n",
    "    \n",
    "    product_descriptions[sku] = input(\"Enter Product Description: \")\n",
    "    print(\"‚úÖ Product description updated successfully!\")\n",
    "\n",
    "\n",
    "def update():\n",
    "    \"\"\"Calls all update functions for sales, product details, and descriptions.\"\"\"\n",
    "    update_sales_data()\n",
    "    update_product_details()\n",
    "    update_product_description()\n",
    "\n",
    "# Call update function when needed\n",
    "print(\"üîÑ Ready to update data\")\n",
    "\n",
    "def dump_data():\n",
    "    \"\"\"Dump updated data into files, ensuring the correct folder structure.\"\"\"\n",
    "    \n",
    "    # Define main folder path\n",
    "    main_folder = \"C:\\\\Users\\\\anish\\\\OneDrive\\\\Documents\\\\GitHub\\\\mainfolder\"\n",
    "\n",
    "    # Ensure main folder exists\n",
    "    os.makedirs(main_folder, exist_ok=True)\n",
    "    \n",
    "    # Convert sales_data dictionary back to DataFrame before saving\n",
    "    df_sales = pd.DataFrame.from_dict(sales_data, orient='index', columns=[f\"Day{i}\" for i in range(1, 15)])\n",
    "    df_sales.insert(0, \"Product_SKU\", df_sales.index)\n",
    "    df_sales.to_csv(os.path.join(main_folder, \"sales_data.csv\"), index=False)\n",
    "    print(\"‚úÖ Sales data successfully written to CSV.\")\n",
    "\n",
    "    # Ensure subfolders exist\n",
    "    product_details_folder = os.path.join(main_folder, \"product_details\")\n",
    "    product_descriptions_folder = os.path.join(main_folder, \"product_descriptions\")\n",
    "    os.makedirs(product_details_folder, exist_ok=True)\n",
    "    os.makedirs(product_descriptions_folder, exist_ok=True)\n",
    "\n",
    "    # Save product details\n",
    "    for sku, details in product_details.items():\n",
    "        with open(os.path.join(product_details_folder, f\"details_{sku}.json\"), \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(details, json_file, indent=4)\n",
    "    print(\"‚úÖ Product details successfully written to JSON files.\")\n",
    "\n",
    "    # Save product descriptions\n",
    "    for sku, description in product_descriptions.items():\n",
    "        with open(os.path.join(product_descriptions_folder, f\"description_{sku}.txt\"), \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(description)\n",
    "    print(\"‚úÖ Product descriptions successfully written to text files.\")\n",
    "\n",
    "# Call dump_data() when needed\n",
    "print(\"üìÇ Ready to dump data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2183f6-af39-4d62-aa92-c7fa201259fc",
   "metadata": {},
   "source": [
    "def fmain():\n",
    "    load_data()\n",
    "print('‚úÖ Data Loaded Successfully')\n",
    "up = input('Do you want to update the data :- (yes/no)').strip().lower()\n",
    "if up == 'yes':\n",
    "    update()\n",
    "    print('update successfully')\n",
    "    dump_data()\n",
    "    load_data()\n",
    "else:\n",
    "    print('thank you !!!!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab20b839-a6e3-4175-b476-8acf3cc26732",
   "metadata": {},
   "source": [
    "load_sales_data(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2a6ca-5365-4650-9ced-f9604ee8dea1",
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "\n",
    "# File paths\n",
    "csv_file = \"C:\\\\Users\\\\anish\\\\OneDrive\\\\Documents\\\\GitHub\\\\mainfolder\\\\sales_data.csv\"\n",
    "json_folder = \"C:\\\\Users\\\\anish\\\\OneDrive\\\\Documents\\\\GitHub\\\\mainfolder\\\\product_details\"\n",
    "txt_folder = \"C:\\\\Users\\\\anish\\\\OneDrive\\\\Documents\\\\GitHub\\\\mainfolder\\\\product_descriptions\"\n",
    "\n",
    "def load_sales_data(csv_file):\n",
    "    \"\"\"Load sales data from a CSV file and return as a DataFrame.\"\"\"\n",
    "    if os.path.exists(csv_file):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        # Ensure 'Product_SKU' column exists\n",
    "        if \"Product_SKU\" not in df.columns:\n",
    "            print(\"‚ùå Error: 'Product_SKU' column not found in CSV!\")\n",
    "            return pd.DataFrame()  # Return empty DataFrame\n",
    "\n",
    "        # Fill missing values with 0 and ensure numerical data\n",
    "        df.fillna(0, inplace=True)\n",
    "\n",
    "        # Convert all day columns to integers\n",
    "        for col in df.columns[1:]:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "        return df\n",
    "    else:\n",
    "        print(\"‚ùå Error: CSV file not found!\")\n",
    "        return pd.DataFrame()  # Return empty DataFrame if file doesn't exist\n",
    "\n",
    "def load_product_details(json_folder):\n",
    "    \"\"\"Load product details from JSON files.\"\"\"\n",
    "    product_details = {}\n",
    "    if os.path.exists(json_folder):\n",
    "        for filename in os.listdir(json_folder):\n",
    "            if filename.startswith(\"details_\") and filename.endswith('.json'):\n",
    "                sku = filename.replace(\"details_\", \"\").replace('.json', '')\n",
    "                with open(os.path.join(json_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                    product_details[sku] = json.load(file)\n",
    "    return product_details\n",
    "\n",
    "def load_product_descriptions(txt_folder):\n",
    "    \"\"\"Load product descriptions from text files.\"\"\"\n",
    "    product_descriptions = {}\n",
    "    if os.path.exists(txt_folder):\n",
    "        for filename in os.listdir(txt_folder):\n",
    "            if filename.startswith(\"description_\") and filename.endswith('.txt'):\n",
    "                sku = filename.replace(\"description_\", \"\").replace('.txt', '')\n",
    "                with open(os.path.join(txt_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                    product_descriptions[sku] = file.read().strip()\n",
    "    return product_descriptions\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load all required data files and display in a formatted way.\"\"\"\n",
    "    sales_data = load_sales_data(csv_file)  # This is now a DataFrame\n",
    "    product_details = load_product_details(json_folder)\n",
    "    product_descriptions = load_product_descriptions(txt_folder)\n",
    "\n",
    "    # Display sales data in tabular format\n",
    "    if not sales_data.empty:\n",
    "        print(\"\\nüìä SALES DATA TABLE:\\n\")\n",
    "        print(tabulate(sales_data, headers=\"keys\", tablefmt=\"grid\", showindex=False))\n",
    "    else:\n",
    "        print(\"‚ö† No sales data available.\")\n",
    "\n",
    "    # Display product details in readable JSON format\n",
    "    print(\"\\nüì¶ PRODUCT DETAILS:\\n\")\n",
    "    for sku, details in product_details.items():\n",
    "        print(f\"SKU: {sku}\")\n",
    "        print(json.dumps(details, indent=4))  # Pretty-print JSON\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Display product descriptions\n",
    "    print(\"\\nüìù PRODUCT DESCRIPTIONS:\\n\")\n",
    "    for sku, description in product_descriptions.items():\n",
    "        print(f\"SKU: {sku}\")\n",
    "        print(description)\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return sales_data, product_details, product_descriptions  # Return the DataFrame directly\n",
    "\n",
    "# Load initial data\n",
    "sales_data, product_details, product_descriptions = load_data()\n",
    "print(\"‚úÖ Data Loaded Successfully\")\n",
    "\n",
    "def validate_sku(sku):\n",
    "    \"\"\"Validate SKU: It should be exactly 13 characters, alphanumeric, and uppercase.\"\"\"\n",
    "    return bool(re.fullmatch(r\"[A-Z0-9]{13}\", sku))\n",
    "\n",
    "def update_sales_data():\n",
    "    \"\"\"Update or add sales data for a product SKU.\"\"\"\n",
    "    global sales_data\n",
    "\n",
    "    sku = input(\"Enter Product Sales SKU: \").strip()\n",
    "    if not validate_sku(sku):\n",
    "        print(\"‚ùå Invalid SKU! It should be exactly 13 characters, alphanumeric, and uppercase.\")\n",
    "        return\n",
    "\n",
    "    if sku in sales_data[\"Product_SKU\"].values:\n",
    "        choice = input(\"This SKU ID is found. Do you want to update the data? (yes/no): \").strip().lower()\n",
    "        if choice != 'yes':\n",
    "            return\n",
    "        day = input(\"Enter specific day to update (1-14) or press Enter to update all days: \")\n",
    "        if day:\n",
    "            day = int(day)\n",
    "            sales = int(input(f\"Enter sales data for Day {day}: \"))\n",
    "            sales_data.loc[sales_data[\"Product_SKU\"] == sku, f\"Day{day}\"] = sales\n",
    "        else:\n",
    "            sales_data_input = input(\"Enter sales data for all 14 days (separated by spaces): \")\n",
    "            sales_values = list(map(int, sales_data_input.split()))\n",
    "            for i, val in enumerate(sales_values):\n",
    "                sales_data.loc[sales_data[\"Product_SKU\"] == sku, f\"Day{i+1}\"] = val\n",
    "    else:\n",
    "        choice = input(\"This SKU ID is not found. Do you want to add new data? (yes/no): \").strip().lower()\n",
    "        if choice != 'yes':\n",
    "            return\n",
    "        sales_data_input = input(\"Enter sales data for all 14 days (separated by spaces): \")\n",
    "        sales_values = list(map(int, sales_data_input.split()))\n",
    "        new_row = {\"Product_SKU\": sku, **{f\"Day{i+1}\": sales_values[i] for i in range(14)}}\n",
    "        sales_data = sales_data.append(new_row, ignore_index=True)\n",
    "\n",
    "    print(\"‚úÖ Sales data updated successfully!\")\n",
    "\n",
    "def dump_data():\n",
    "    \"\"\"Dump updated data into files, ensuring the correct folder structure.\"\"\"\n",
    "    main_folder = \"C:\\\\Users\\\\anish\\\\OneDrive\\\\Documents\\\\GitHub\\\\mainfolder\"\n",
    "\n",
    "    os.makedirs(main_folder, exist_ok=True)\n",
    "\n",
    "    # Save sales data\n",
    "    sales_data.to_csv(os.path.join(main_folder, \"sales_data.csv\"), index=False)\n",
    "    print(\"‚úÖ Sales data successfully written to CSV.\")\n",
    "\n",
    "    product_details_folder = os.path.join(main_folder, \"product_details\")\n",
    "    product_descriptions_folder = os.path.join(main_folder, \"product_descriptions\")\n",
    "\n",
    "    os.makedirs(product_details_folder, exist_ok=True)\n",
    "    os.makedirs(product_descriptions_folder, exist_ok=True)\n",
    "\n",
    "    for sku, details in product_details.items():\n",
    "        with open(os.path.join(product_details_folder, f\"details_{sku}.json\"), \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(details, json_file, indent=4)\n",
    "\n",
    "    print(\"‚úÖ Product details successfully written to JSON files.\")\n",
    "\n",
    "    for sku, description in product_descriptions.items():\n",
    "        with open(os.path.join(product_descriptions_folder, f\"description_{sku}.txt\"), \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(description)\n",
    "\n",
    "    print(\"‚úÖ Product descriptions successfully written to text files.\")\n",
    "\n",
    "print(\"üìÇ Ready to dump data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8bf8b9c3-7f4a-485a-bdaf-f1e174615600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Product Sales SKU:  123456789123H\n",
      "This SKU ID is found. Do you want to update the data? (yes/no):  yes\n",
      "Enter specific day to update (1-14) or press Enter to update all days:  1\n",
      "Enter sales data for Day 1:  200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sales data updated successfully!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Product Detail SKU:  123456789123H\n",
      "Enter Product Name:  gaming laptop\n",
      "Enter Brand:  lenevo\n",
      "Enter Model:  v15\n",
      "Enter Specifications:  athlon gold\n",
      "Enter Price:  37000\n",
      "Enter Availability:  in stock \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Product details updated successfully!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Product Description SKU:  123456789123H\n",
      "Enter Product Description:  amazing laptop with power house performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Product description updated successfully!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "006a4d3a-c8c6-44f1-a626-209397da2f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Loaded Successfully\n",
      "‚úÖ Sales data updated successfully!\n",
      "‚úÖ Product details updated successfully!\n",
      "‚úÖ Product description updated successfully!\n",
      "‚úÖ Sales data successfully written to CSV.\n",
      "‚úÖ Product details successfully written to JSON files.\n",
      "‚úÖ Product descriptions successfully written to text files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "\n",
    "# File paths\n",
    "main_folder = \"C:\\\\Users\\\\anish\\\\OneDrive\\\\Documents\\\\GitHub\\\\mainfolder\"\n",
    "csv_file = os.path.join(main_folder, \"sales_data.csv\")\n",
    "json_folder = os.path.join(main_folder, \"product_details\")\n",
    "txt_folder = os.path.join(main_folder, \"product_descriptions\")\n",
    "\n",
    "def load_sales_data(csv_file):\n",
    "    \"\"\"Load sales data from a CSV file and return as a DataFrame.\"\"\"\n",
    "    if os.path.exists(csv_file):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        if \"Product_SKU\" not in df.columns:\n",
    "            print(\"‚ùå Error: 'Product_SKU' column not found in CSV!\")\n",
    "            return pd.DataFrame()\n",
    "        df.fillna(0, inplace=True)\n",
    "        for col in df.columns[1:]:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"‚ùå Error: CSV file not found!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_product_details(json_folder):\n",
    "    \"\"\"Load product details from JSON files.\"\"\"\n",
    "    product_details = {}\n",
    "    if os.path.exists(json_folder):\n",
    "        for filename in os.listdir(json_folder):\n",
    "            if filename.startswith(\"details_\") and filename.endswith('.json'):\n",
    "                sku = filename.replace(\"details_\", \"\").replace('.json', '')\n",
    "                with open(os.path.join(json_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                    product_details[sku] = json.load(file)\n",
    "    return product_details\n",
    "\n",
    "def load_product_descriptions(txt_folder):\n",
    "    \"\"\"Load product descriptions from text files.\"\"\"\n",
    "    product_descriptions = {}\n",
    "    if os.path.exists(txt_folder):\n",
    "        for filename in os.listdir(txt_folder):\n",
    "            if filename.startswith(\"description_\") and filename.endswith('.txt'):\n",
    "                sku = filename.replace(\"description_\", \"\").replace('.txt', '')\n",
    "                with open(os.path.join(txt_folder, filename), 'r', encoding='utf-8') as file:\n",
    "                    product_descriptions[sku] = file.read().strip()\n",
    "    return product_descriptions\n",
    "\n",
    "def validate_sku(sku):\n",
    "    \"\"\"Validate SKU: It should be exactly 13 characters, alphanumeric, and uppercase.\"\"\"\n",
    "    return bool(re.fullmatch(r\"[A-Z0-9]{13}\", sku))\n",
    "\n",
    "def update_sales_data(sku, sales_values):\n",
    "    \"\"\"Update or add sales data for a product SKU.\"\"\"\n",
    "    global sales_data\n",
    "    if sku in sales_data[\"Product_SKU\"].values:\n",
    "        for i, val in enumerate(sales_values):\n",
    "            sales_data.loc[sales_data[\"Product_SKU\"] == sku, f\"Day{i+1}\"] = val\n",
    "    else:\n",
    "        new_row = {\"Product_SKU\": sku, **{f\"Day{i+1}\": sales_values[i] for i in range(14)}}\n",
    "        sales_data = sales_data.append(new_row, ignore_index=True)\n",
    "    print(\"‚úÖ Sales data updated successfully!\")\n",
    "\n",
    "def update_product_details(sku, name, brand, model, specs, price, availability):\n",
    "    \"\"\"Update or add product details.\"\"\"\n",
    "    product_details[sku] = {\n",
    "        \"Product Name\": name,\n",
    "        \"Brand\": brand,\n",
    "        \"Model\": model,\n",
    "        \"Specifications\": specs,\n",
    "        \"Price\": price,\n",
    "        \"Availability\": availability\n",
    "    }\n",
    "    print(\"‚úÖ Product details updated successfully!\")\n",
    "\n",
    "def update_product_description(sku, description):\n",
    "    \"\"\"Update or add product description.\"\"\"\n",
    "    product_descriptions[sku] = description\n",
    "    print(\"‚úÖ Product description updated successfully!\")\n",
    "\n",
    "def update():\n",
    "    \"\"\"Collect input and update all records.\"\"\"\n",
    "    sku = input(\"Enter Product SKU: \").strip()\n",
    "    if not validate_sku(sku):\n",
    "        print(\"‚ùå Invalid SKU! It should be exactly 13 characters, alphanumeric, and uppercase.\")\n",
    "        return\n",
    "    \n",
    "    sales_data_input = input(\"Enter sales data for all 14 days (separated by spaces): \")\n",
    "    sales_values = list(map(int, sales_data_input.split()))\n",
    "    if len(sales_values) != 14:\n",
    "        print(\"‚ùå Sales data must contain exactly 14 values.\")\n",
    "        return\n",
    "    \n",
    "    name = input(\"Enter Product Name: \")\n",
    "    brand = input(\"Enter Brand: \")\n",
    "    model = input(\"Enter Model: \")\n",
    "    specs = input(\"Enter Specifications: \")\n",
    "    price = input(\"Enter Price: \")\n",
    "    availability = input(\"Enter Availability: \")\n",
    "    description = input(\"Enter Product Description: \")\n",
    "    \n",
    "    update_sales_data(sku, sales_values)\n",
    "    update_product_details(sku, name, brand, model, specs, price, availability)\n",
    "    update_product_description(sku, description)\n",
    "    print(\"‚úÖ All product details updated successfully!\")\n",
    "\n",
    "def dump_data():\n",
    "    \"\"\"Dump updated data into files.\"\"\"\n",
    "    os.makedirs(main_folder, exist_ok=True)\n",
    "    sales_data.to_csv(csv_file, index=False)\n",
    "    print(\"‚úÖ Sales data successfully written to CSV.\")\n",
    "    \n",
    "    os.makedirs(json_folder, exist_ok=True)\n",
    "    os.makedirs(txt_folder, exist_ok=True)\n",
    "    \n",
    "    for sku, details in product_details.items():\n",
    "        with open(os.path.join(json_folder, f\"details_{sku}.json\"), \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json.dump(details, json_file, indent=4)\n",
    "    print(\"‚úÖ Product details successfully written to JSON files.\")\n",
    "    \n",
    "    for sku, description in product_descriptions.items():\n",
    "        with open(os.path.join(txt_folder, f\"description_{sku}.txt\"), \"w\", encoding=\"utf-8\") as txt_file:\n",
    "            txt_file.write(description)\n",
    "    print(\"‚úÖ Product descriptions successfully written to text files.\")\n",
    "\n",
    "# Load initial data\n",
    "sales_data = load_sales_data(csv_file)\n",
    "product_details = load_product_details(json_folder)\n",
    "product_descriptions = load_product_descriptions(txt_folder)\n",
    "print(\"‚úÖ Data Loaded Successfully\")\n",
    "\n",
    "# Example of updating with given data\n",
    "update_sales_data(\"CMWKCILOP27KF\", [8, 14, 16, 7, 15, 21, 14, 16, 32, 29, 26, 30, 25, 22])\n",
    "update_product_details(\"CMWKCILOP27KF\", \"Pokemon Card\", \"GameFreak\", \"ScarletViolet151\", \"Genuine, TCG, English\", \"$1.99\", \"In stock\")\n",
    "update_product_description(\"CMWKCILOP27KF\", \"Original Pokemon TCG Pikachu card\")\n",
    "\n",
    "dump_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ecba858f-77b4-4b1a-af46-e78ad57d5f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Loaded Successfully\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to update the data :- (yes/no) yes\n",
      "Enter Product SKU:  123456789123H\n",
      "Enter sales data for all 14 days (separated by spaces):  1 2 3 4 5 6 7 8 9 10 11 12 13 14\n",
      "Enter Product Name:  jbchuvs\n",
      "Enter Brand:  hjasvcv\n",
      "Enter Model:  bcuvicv\n",
      "Enter Specifications:  ucvycv\n",
      "Enter Price:  cjhvdiyv\n",
      "Enter Availability:  vdcv\n",
      "Enter Product Description:  hjvcydv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sales data updated successfully!\n",
      "‚úÖ Product details updated successfully!\n",
      "‚úÖ Product description updated successfully!\n",
      "‚úÖ All product details updated successfully!\n",
      "update successfully\n",
      "‚úÖ Sales data successfully written to CSV.\n",
      "‚úÖ Product details successfully written to JSON files.\n",
      "‚úÖ Product descriptions successfully written to text files.\n",
      "\n",
      "üìä SALES DATA TABLE:\n",
      "\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| Product_SKU    |   Day1 |   Day2 |   Day3 |   Day4 |   Day5 |   Day6 |   Day7 |   Day8 |   Day9 |   Day10 |   Day11 |   Day12 |   Day13 |   Day14 |\n",
      "+================+========+========+========+========+========+========+========+========+========+=========+=========+=========+=========+=========+\n",
      "| AISJDKFJW93NJ  |    100 |     12 |     15 |     18 |     20 |     22 |     25 |     28 |     26 |      30 |      32 |      29 |      27 |      24 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| DJKFIEI432FIE  |      8 |     10 |     12 |     15 |     20 |     18 |     14 |     13 |     17 |      10 |       8 |      11 |      14 |      16 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| GGOENEBJ079499 |     15 |     18 |     22 |     25 |     28 |     20 |     17 |     23 |     19 |      21 |      24 |      27 |      18 |      20 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| HJSKNWK429DJE  |     30 |     32 |     35 |     38 |     40 |     42 |     45 |     48 |     50 |      52 |      55 |      53 |      49 |      47 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| JFKL3940NFKLJ  |     18 |     20 |     22 |     25 |     28 |     30 |     32 |     35 |     38 |      36 |      33 |      29 |      26 |      24 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| LKDFJ49LSDJKL  |     25 |     28 |     30 |     32 |     35 |     38 |     42 |     40 |     37 |      34 |      36 |      31 |      29 |      27 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| MWKDI3JFK39SL  |     30 |     35 |     40 |     45 |     50 |     42 |     37 |     38 |     41 |      36 |      33 |      39 |      40 |      44 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| NEKFJOWE9FDIW  |     12 |     15 |     18 |     20 |     22 |     24 |     21 |     23 |     25 |      28 |      30 |      27 |      26 |      29 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| OWEJL398FWJLK  |     20 |     22 |     25 |     28 |     30 |     32 |     35 |     38 |     36 |      33 |      29 |      26 |      24 |      27 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| XPLFJW2490XJN  |      5 |      8 |      9 |     12 |     15 |     10 |     14 |     16 |     20 |      18 |      22 |      25 |      19 |      21 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| CMWKCILOP27KF  |      8 |     14 |     16 |      7 |     15 |     21 |     14 |     16 |     32 |      29 |      26 |      30 |      25 |      22 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| CMWKCILOP27KS  |     10 |     12 |     13 |     14 |     15 |     16 |     17 |     18 |     19 |      20 |      21 |      22 |      23 |      24 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| ABCDEFZHUTNH1  |    100 |    200 |      3 |      4 |      5 |      7 |    800 |    900 |    100 |     110 |     120 |     130 |     140 |     150 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "| 123456789123H  |      1 |      2 |      3 |      4 |      5 |      6 |      7 |      8 |      9 |      10 |      11 |      12 |      13 |      14 |\n",
      "+----------------+--------+--------+--------+--------+--------+--------+--------+--------+--------+---------+---------+---------+---------+---------+\n",
      "\n",
      "üì¶ PRODUCT DETAILS:\n",
      "\n",
      "SKU: 123456789123H\n",
      "{\n",
      "    \"Product Name\": \"jbchuvs\",\n",
      "    \"Brand\": \"hjasvcv\",\n",
      "    \"Model\": \"bcuvicv\",\n",
      "    \"Specifications\": \"ucvycv\",\n",
      "    \"Price\": \"cjhvdiyv\",\n",
      "    \"Availability\": \"vdcv\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: ABCDEFZHUTNH1\n",
      "{\n",
      "    \"product_name\": \"SONY BRAVIA\",\n",
      "    \"brand\": \"SONY\",\n",
      "    \"model\": \"TV-210\",\n",
      "    \"specifications\": \"LED\",\n",
      "    \"price\": \"1400$\",\n",
      "    \"availability\": \"IN STOCK\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: AISJDKFJW93NJ\n",
      "{\n",
      "    \"product_name\": \"apple\",\n",
      "    \"brand\": \"apple\",\n",
      "    \"model\": \"iphone15\",\n",
      "    \"specifications\": \"great sm\",\n",
      "    \"price\": \"900$\",\n",
      "    \"availability\": \"in stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: CMWKCILOP27KF\n",
      "{\n",
      "    \"Product Name\": \"Pokemon Card\",\n",
      "    \"Brand\": \"GameFreak\",\n",
      "    \"Model\": \"ScarletViolet151\",\n",
      "    \"Specifications\": \"Genuine, TCG, English\",\n",
      "    \"Price\": \"$1.99\",\n",
      "    \"Availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: CMWKCILOP27KH\n",
      "{\n",
      "    \"product_name\": \"samsang a35\",\n",
      "    \"brand\": \"samsang\",\n",
      "    \"model\": \"a35\",\n",
      "    \"specifications\": \"best phone\",\n",
      "    \"price\": \"500$\",\n",
      "    \"availability\": \"in stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: CMWKCILOP27KS\n",
      "{\n",
      "    \"product_name\": \"i phone 15 \",\n",
      "    \"brand\": \"apple.inc\",\n",
      "    \"model\": \"15\",\n",
      "    \"specifications\": \"48 mp camera, dynamic island\",\n",
      "    \"price\": \"1500\",\n",
      "    \"availability\": \"in stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: DJKFIEI432FIE\n",
      "{\n",
      "    \"product_name\": \"Men's Running Shoes\",\n",
      "    \"brand\": \"RunFit\",\n",
      "    \"model\": \"SpeedX-500\",\n",
      "    \"specifications\": \"Size 10, Lightweight design, Breathable material\",\n",
      "    \"price\": \"$79.99\",\n",
      "    \"availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: GGOENEBJ079499\n",
      "{\n",
      "    \"product_name\": \"Smartphone\",\n",
      "    \"brand\": \"XYZ Electronics\",\n",
      "    \"model\": \"ABC-2000\",\n",
      "    \"specifications\": \"6.5-inch display, 128GB storage, 16MP camera\",\n",
      "    \"price\": \"$499.99\",\n",
      "    \"availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: HJSKNWK429DJE\n",
      "{\n",
      "    \"product_name\": \"Wireless Earbuds\",\n",
      "    \"brand\": \"SoundSync\",\n",
      "    \"model\": \"TunePro-2022\",\n",
      "    \"specifications\": \"Bluetooth 5.0, 20 hours battery life, Touch controls\",\n",
      "    \"price\": \"$89.99\",\n",
      "    \"availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: JFKL3940NFKLJ\n",
      "{\n",
      "    \"product_name\": \"Resistance Bands Set\",\n",
      "    \"brand\": \"FitFlex\",\n",
      "    \"model\": \"StrengthPro-300\",\n",
      "    \"specifications\": \"5 bands, Varying resistance levels, Portable\",\n",
      "    \"price\": \"$34.99\",\n",
      "    \"availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: LKDFJ49LSDJKL\n",
      "{\n",
      "    \"product_name\": \"Anti-Aging Face Cream\",\n",
      "    \"brand\": \"GlowBeauty\",\n",
      "    \"model\": \"AgeDefy-300\",\n",
      "    \"specifications\": \"Natural ingredients, Hydrating formula\",\n",
      "    \"price\": \"$39.99\",\n",
      "    \"availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: MWKDI3JFK39SL\n",
      "{\n",
      "    \"product_name\": \"Fictional Novel\",\n",
      "    \"brand\": \"BestBooks\",\n",
      "    \"model\": null,\n",
      "    \"specifications\": \"Paperback, 300 pages\",\n",
      "    \"price\": \"$14.99\",\n",
      "    \"availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: NEKFJOWE9FDIW\n",
      "{\n",
      "    \"product_name\": \"Board Game\",\n",
      "    \"brand\": \"FamilyFun\",\n",
      "    \"model\": \"GameNight-2022\",\n",
      "    \"specifications\": \"2-6 players, Ages 8 and up\",\n",
      "    \"price\": \"$29.99\",\n",
      "    \"availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: OWEJL398FWJLK\n",
      "{\n",
      "    \"product_name\": \"Yoga Mat\",\n",
      "    \"brand\": \"ZenFitness\",\n",
      "    \"model\": \"EcoMat-500\",\n",
      "    \"specifications\": \"Non-slip, 6mm thickness, Eco-friendly material\",\n",
      "    \"price\": \"$19.99\",\n",
      "    \"availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "SKU: XPLFJW2490XJN\n",
      "{\n",
      "    \"product_name\": \"Robot Vacuum Cleaner\",\n",
      "    \"brand\": \"CleanTech\",\n",
      "    \"model\": \"AutoSweep-9000\",\n",
      "    \"specifications\": \"Smart navigation, HEPA filter, 90 minutes runtime\",\n",
      "    \"price\": \"$249.99\",\n",
      "    \"availability\": \"In stock\"\n",
      "}\n",
      "--------------------------------------------------\n",
      "\n",
      "üìù PRODUCT DESCRIPTIONS:\n",
      "\n",
      "SKU: 123456789123H\n",
      "hjvcydv\n",
      "--------------------------------------------------\n",
      "SKU: AISJDKFJW93NJ\n",
      "great smartphone\n",
      "--------------------------------------------------\n",
      "SKU: CMWKCILOP27KF\n",
      "Original Pokemon TCG Pikachu card\n",
      "--------------------------------------------------\n",
      "SKU: CMWKCILOP27KH\n",
      "this phone has 50 mp camera with  6gb of ram\n",
      "--------------------------------------------------\n",
      "SKU: CMWKCILOP27KS\n",
      "CMWKCILOP27KS\n",
      "--------------------------------------------------\n",
      "SKU: DJKFIEI432FIE\n",
      "Elevate your running experience with the RunFit SpeedX-500 Men's Running Shoes.\n",
      "Designed for performance, these shoes feature a lightweight design, breathable material, and are available in vibrant Red, Blue, and classic Black.\n",
      "Whether you're a seasoned runner or just starting, these shoes provide comfort and support for every stride, ensuring you reach new milestones effortlessly.\n",
      "--------------------------------------------------\n",
      "SKU: GGOENEBJ079499\n",
      "Dive into the future with the XYZ Electronics Smartphone, model ABC-2000.\n",
      "Boasting a 6.5-inch display, 128GB storage, and a 16MP camera, this powerful device redefines the smartphone experience.\n",
      "With a sleek design and available in Black, Silver, and Blue, it combines cutting-edge technology with style, ensuring you stay connected in the most sophisticated way possible.\n",
      "--------------------------------------------------\n",
      "SKU: HJSKNWK429DJE\n",
      "Immerse yourself in superior audio quality with SoundSync's TunePro-2022 Wireless Earbuds.\n",
      "Featuring Bluetooth 5.0, 20 hours of battery life, and touch controls, these earbuds deliver a seamless and immersive listening experience.\n",
      "Available in Black and White, they combine style with functionality for music lovers on the go. \n",
      "With a 4.7/5 stars rating, they stand out as a top choice in the realm of wireless audio.\n",
      "--------------------------------------------------\n",
      "SKU: JFKL3940NFKLJ\n",
      "Embrace versatility in your workouts with FitFlex's StrengthPro-300 Resistance Bands Set.\n",
      "With 5 bands offering varying resistance levels and portability, this set is your go-to for effective strength training.\n",
      "Available in Red, Yellow, and Blue, it caters to different fitness levels and adds a dynamic dimension to your exercise routine.\n",
      "--------------------------------------------------\n",
      "SKU: LKDFJ49LSDJKL\n",
      "Rediscover youthful radiance with GlowBeauty's AgeDefy-300 Anti-Aging Face Cream.\n",
      "Formulated with natural ingredients and a hydrating formula, this skincare essential rejuvenates and nourishes your skin, leaving you with a vibrant and refreshed complexion.\n",
      "With a stellar 4.7/5 stars rating, it's a must-have for those embracing the journey to ageless beauty.\n",
      "--------------------------------------------------\n",
      "SKU: MWKDI3JFK39SL\n",
      "Immerse yourself in the world of storytelling with BestBooks' Fictional Novel.\n",
      "This paperback, spanning 300 pages, promises a captivating journey through the pages of an engaging narrative.\n",
      "Ideal for avid readers seeking an escape, this novel, with a 4.6/5 stars rating, is a testament to its ability to weave a compelling tale that keeps you hooked until the last page.\n",
      "--------------------------------------------------\n",
      "SKU: NEKFJOWE9FDIW\n",
      "Unleash the fun with FamilyFun's GameNight-2022 Board Game.\n",
      "Designed for 2-6 players and suitable for ages 8 and up, this exciting game promises laughter and bonding moments for the entire family.\n",
      "With a 4.4/5 stars rating, it's a testament to its ability to turn any ordinary night into an extraordinary game night filled with friendly competition and shared joy.\n",
      "--------------------------------------------------\n",
      "SKU: OWEJL398FWJLK\n",
      "Elevate your yoga practice with ZenFitness' EcoMat-500 Yoga Mat.\n",
      "Featuring a non-slip surface, 6mm thickness, and eco-friendly materials, this high-quality mat provides the perfect foundation for your workouts.\n",
      "Available in Purple, Green, and Blue, it not only enhances your comfort but also adds a touch of serenity to your exercise routine.\n",
      "--------------------------------------------------\n",
      "SKU: XPLFJW2490XJN\n",
      "Introducing the CleanTech AutoSweep-9000 Robot Vacuum Cleaner ‚Äì your smart companion for automated cleaning.\n",
      "With smart navigation, a HEPA filter, and a runtime of 90 minutes, this efficient device takes care of your cleaning needs.\n",
      "Available in White and Silver, it blends seamlessly into your home, making cleanliness a hassle-free experience.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def fmain():\n",
    "    load_data()\n",
    "print('‚úÖ Data Loaded Successfully')\n",
    "up = input('Do you want to update the data :- (yes/no)').strip().lower()\n",
    "if up == 'yes':\n",
    "    update()\n",
    "    print('update successfully')\n",
    "    dump_data()\n",
    "    load_data()\n",
    "else:\n",
    "    print('thank you !!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a3ae4d-40d1-4517-b805-58a2cf8c117d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e550b8-a5c4-47f9-963d-e4cdcb0596e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e47b230-4b43-480f-8d86-6cb45ba66a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
